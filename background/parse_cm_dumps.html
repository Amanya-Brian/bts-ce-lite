<h1>Background process</h1>
<script type="text/javascript">
	
const {ipcRenderer} = window.require('electron');
const { app, process } = window.require('electron').remote;
const { spawn, spawnSync } = window.require('child_process') 
const path = window.require('path');
const isDev = window.require('electron-is-dev');
const replace = window.require('replace-in-file');
const fs = window.require('fs');
const readChunk = window.require('read-chunk');
const fileType = window.require('file-type');
const gunzip = window.require('gunzip-file')
const log = window.require('electron-log');
const tar = window.require('tar');
const unzip = window.require('unzipper');
const unrar = window.require("node-unrar-js");
const fstream = window.require("fstream");
//const sync = window.require('sync');

log.info(`[parse_cm_job] Starting hidden window to parse cm files away from renderer process`)

const VENDOR_PARSERS = {
	'ERICSSON': {
		'BULKCM': 'boda-bulkcmparser.jar',
		'CNAIV2': 'boda-ericssoncnaiparser.jar',
	},
	'HUAWEI': {
		'GEXPORT_XML': 'boda-huaweicmobjectparser.jar',
		'CFGMML': 'boda-huaweimmlparser.jar',
		'NBI_XML': 'boda-huaweicmxmlparser.jar'
	},
	'ZTE': {
		'BULKCM': 'boda-bulkcmparser.jar',
		'XLS': 'boda_ztexlscmparser.jar',
	},
	'NOKIA': {
		'RAML': 'boda-nokiacmdataparser.jar'
	}
}

/*
* Extract rar file into targetFolder
*
* @param string fileName Name of file to extract 
* @param string targetFolder Name of destination folder
*/
extractRar = (fileName, targetFolder) => {
	try{
		var extractor = unrar.createExtractorFromFile(fileName, targetFolder);
		extractor.extractAll();
	}catch(e){
		log.error(e);
	}
}


/*
* Extract gz file into targetFolder
*
* @param string fileName Name of file to extract 
* @param string targetFolder Name of destination folder
*/
extractGzip =  (fileName, targetFolder) => {
	console.log("Running extractGzip ....")
	const targetFile = path.join(targetFolder, path.basename(fileName).replace(".gz",""));
	gunzip( fileName, targetFile);
	
}

/*
* Extract tar file into targetFolder
*
* @param string fileName Name of file to extract 
* @param string targetFolder Name of destination folder
*/
extractTar = (fileName, targetFolder) => {
	tar.x(  // or tar.extract(
	  {
		file: fileName,
		cwd: targetFolder,
		sync : true
	  }
	);
}

/*
* Unzip file into targetFolder
*
* @param string fileName Name of file to unzip 
* @param string targetFolder Name of destination folder
*/
extractZip = (fileName, targetFolder) => {
	/*var readStream = fs.createReadStream(fileName);
	let newFile = path.join(targetFolder, path.basename(fileName).replace(".zip", ""));
	
	log.info(`newFile: ${newFile}`);
	var writeStream = fstream.Writer(newFile);
	 
	readStream
	  .pipe(unzip.Parse())
	  .pipe(writeStream);
	  */
	  
	  fs.createReadStream(fileName).pipe(unzip.Extract({ path: targetFolder }));
}

/*
* Retun the extension and mime type of a file
*
* @param string filename 
*/
getFileType = (filename) => {
	let buffer = readChunk.sync(filename, 0, fileType.minimumBytes);
	return fileType(buffer);
}

/**
* Uncompress files in given folder 
* @param string folderName
*/
uncompressFiles = async (folderName) => {
	ipcRenderer.send('parse-cm-job', JSON.stringify({status:"info", message: `Uncompressing files in ${folderName} ... `}));
	log.info(`[parse_cm_job] Uncompressing files in ${folderName} ...`)
	let files = fs.readdirSync(folderName,  { withFileTypes: true }).filter(dirent => !dirent.isDirectory()).map(dirent => dirent.name);
	
	let promiseArray = []
	
	for (let i=0; i<files.length; i++) {
		let filename = files[i];
		let filePath = path.join(folderName,filename)
		let fType = getFileType(filePath);
		
		try{
			if(fType.ext === 'gz' && fType.mime === 'application/gzip') {
				promiseArray.push(
					new Promise((resolve, reject) => {
					
						gunzip( filePath, filePath.replace('.gz',''), function() {
							ipcRenderer.send('parse-cm-job', JSON.stringify({status:"info", message: `Uncompressed  ${filename}. `}));
							log.info(`[parse_cm_job] Uncompressed  ${filename} successfully.`)

							resolve(`Uncompressed  ${filename}. `)
						});
						
					})
				);
			}else{
				log.info(`[parse_cm_job] Skip uncompressing of ${filePath}`)
			}
		}catch(e){
			log.info(`[parse_cm_job] file:${filename} fType:${fType} error:${e.toString()}`)
		}
	}
	
	let r = await Promise.all(promiseArray)
	return r
}

/*
* Use gunzip on windows.
* This is a work around to handle large files which are a problem for nodejs
* 
* @param string inputFile 
*/
winGunzipFile = (inputFile) => {
	let libPath = app.getAppPath();

	if (!isDev) {
	  libPath = process.resourcesPath;
	} 

	const gzip = path.join(libPath,'libraries','gzip.exe');
		
	const child = spawnSync(gzip, ['-d', inputFile]);
	log.info(`${gzip} -d ${inputFile}`);

	if(child.error){
		throw child.error.toString();
	}
}


/*
* Uncompress with 7z
*
*@param string fileName
*@param string targetFolder
*/
unCompressFile = (fileName, targetFolder) => {
	let libPath = app.getAppPath();
	if (!isDev) {
	  libPath = process.resourcesPath;
	} 

	//Windows
	if(process.platform === "win32"){
		let sevenZip = path.join(libPath,'libraries','7z.exe');

		const child = spawnSync(sevenZip, ['e', fileName,"-o"+targetFolder]);
		
		log.info(`${sevenZip} e ${fileName} -o${targetFolder}`);

		log.info(`${child.stderr.toString()}`);
		
		if(child.error){
			throw child.error.toString();
		}else{
			log.info(child.stdout.toString());	
		}
	
	}else{
	
		let mime = getFileType(fileName).mime;
		
		//zip
		if(mime === 'application/zip'){
			extractZip(fileName, targetFolder);
		}
	
		//tar or tgz/tar.gz
		if(mime === 'application/x-tar' || 'application/x-gtar'){
			extractTar(fileName, targetFolder);
		}
		
		//rar
		if(mime === 'application/x-rar-compressed'){
			extractRar(fileName, targetFolder);
		}
		
		//gz
		if(mime === 'application/gzip'){
			extractGzip(fileName, targetFolder);
		}

	}
}

/*
* Uncompress gz files in a folder 
*
*@param string folderName
*/
uncompressFolder = (folderName) => {

	/**
	*Create backup folder for originals
	*/
	log.info(`[parse_cm_job] Create folder for original version of modified files(originals)...`);
	const originalsBackup = path.join(folderName,'originals');
	if (!fs.existsSync(originalsBackup)) {
		fs.mkdirSync(originalsBackup)	
	}
	
	let files = fs.readdirSync(folderName,  { withFileTypes: true }).filter(dirent => !dirent.isDirectory()).map(dirent => dirent.name);
	for (let i=0; i<files.length; i++) {
		let filePath = path.join(folderName,files[i]);
		let fType = getFileType(filePath);
		
		try{
			if( fType.mime === 'application/gzip' || 
			fType.mime === 'application/zip' || 
			fType.mime === 'application/x-rar-compressed' || 
			fType.mime === 'application/x-tar' ||
			fType.mime === 'application/x-bzip2' ||
			fType.mime === 'application/x-lzip' ||
			fType.mime === 'application/x-lzma' ||
			fType.mime === 'application/x-7z-compressed' ||
			fType.mime === 'application/x-gtar'
			) {
				log.info(`Uncompressing ${files[i]}...`);
				ipcRenderer.send('parse-cm-job', JSON.stringify({status:"info", message: `Uncompressing  ${files[i]}...`}));
				unCompressFile(filePath,folderName);
				
				//Move
				let newPath = path.join(originalsBackup, files[i]);
				fs.renameSync(filePath, newPath)
				
			}else{
				log.info(`[parse_cm_job] Skip uncompressing of ${filePath}`)
			}
		}catch(e){
			log.info(`[parse_cm_job] file:${filePath} fType:${fType.toString()} error:${e.toString()}`);
			log.error(`[parse_cm_job] file:${filePath} fType:${fType.toString()} error:${e.toString()}`);
		}
	}
}

/**
* Clean Huawei GExport files.
*
*	sed -i -r "
*	s/_(BSC6900GSM|BSC6900UMTS|BSC6900GU|BSC6910GSM|BSC6910UMTS|BSC6910GU)//ig;
*	s/_(BTS3900|PICOBTS3900|BTS3911B|PICOBTS3911B|MICROBTS3900|MICROBTS3911B)//ig;
*	s/BSC(6910|6900)(UMTS|GSM)Function/FUNCTION/ig;
*	s/BSC(6910|6900)Equipment/EQUIPMENT/ig;
*	s/<class name=\"(.*)\"/<class name=\"\U\1\"/ig;
*	s/<class name=\"(.*)_MSCSERVER/<class name=\"\1/ig;
*	s/<class name=\"(.*)_ENODEB\"/<class name=\"\1\"/ig;
*	s/<class name=\"(.*)3900/<class name=\"\1/ig;
*	" /mediation/data/cm/huawei/raw/gexport/*.xml
*
* @exportFolder String Folder with the GExport dump XML files to be cleaned
*/
cleanHuaweiGexportFiles = async (exportFolder) => {	
	const replaceOptions = {
	  files: path.join(exportFolder,'*'),
	  from: [
		/_(BSC6900GSM|BSC6900UMTS|BSC6900GU|BSC6910GSM|BSC6910UMTS|BSC6910GU)/ig,
		/_(BTS3900|PICOBTS3900|BTS3911B|PICOBTS3911B|MICROBTS3900|MICROBTS3911B)/ig,
		/BSC(6910|6900)(UMTS|GSM)Function/ig,
		/BSC(6910|6900)Equipment/ig,
		/<class name=\"(.*)\"/ig,
		/<class name=\"(.*)_MSCSERVER/ig,
		/<class name=\"(.*)_ENODEB\"/ig,
		/<class name=\"(.*)3900/
	  ],
	  to: [
		"",
		"",
		"FUNCTION",
		"EQUIPMENT",
		(matchStr) => "<class name=\"" + matchStr.match(/<class name=\"(.*)\"/)[1].toUpperCase() + "\"",
		(matchStr) => "<class name=\"" + matchStr.match(/<class name=\"(.*)_MSCSERVER/)[1],
		(matchStr) => "<class name=\"" + matchStr.match(/<class name=\"(.*)_ENODEB\"/)[1] + "\"",
		(matchStr) => "<class name=\"" + matchStr.match(/<class name=\"(.*)3900/)[1]
	  ],
	};
	
	return await replace.sync(replaceOptions)
    
}


/*Use gnu sed.exe on windows
* 
*/
cleanHuaweiGExportWithSed = (inputFolder) => {
	let libPath = app.getAppPath();

	if (!isDev) {
	  libPath = process.resourcesPath;
	} 
	
	let files = fs.readdirSync(inputFolder,  { withFileTypes: true }).filter(dirent => !dirent.isDirectory()).map(dirent => dirent.name);
		
	const sedScript = path.join(libPath,'libraries', 'gexport_cleanup.sed');
	const sed = path.join(libPath,'libraries','sed.exe');
		
	for (let i=0; i<files.length; i++) {
		f = files[i];
		inputFile = path.join(inputFolder,f);
		
		log.info(`Cleaning ${f}...`);
		ipcRenderer.send('parse-cm-job', JSON.stringify({status:"info", message: `Cleaning  ${f}...`}));
		
		const child = spawnSync(sed, ['-i', '-r', '-f', sedScript, inputFile]);
		log.info(`${sed} -i -r -f ${sedScript} ${inputFile}`);

		if(child.error){
			log.info(`[parse_cm_job] error:${child.error.toString()}`);
			//ipcRenderer.send('parse-cm-job', JSON.stringify({status:"error", message: child.stderr.toString()}));
			throw child.error.toString();
		}
	}

}

/*
* Take the latest file when there is more than one file from the same node .
*
8 @param pathToFolder The name of the folder containing the GExport XML CM dumps
*/
removeDublicateHuaweiGExportFiles = (pathToFolder) => {
	
	//Create temp folder
	const repeatedFilesFolder = path.join(pathToFolder,'repeated_files');
	
	ipcRenderer.send('parse-cm-job', JSON.stringify({status:"info", message: `Creating folder for duplicate files: ${repeatedFilesFolder} ... `}));
	log.info(`[parse_cm_job] Creating folder for duplicate files: ${repeatedFilesFolder} ... `)
	
	if (!fs.existsSync(repeatedFilesFolder)) {
		fs.mkdirSync(repeatedFilesFolder)	
	}

	log.info("[parse_cm_job] Starting removal of duplicate gexport files...")
	ipcRenderer.send('parse-cm-job', JSON.stringify({status:"info", message: "Starting removal of duplicate gexport files..."}));
	//Key - value pair of node and the most recent file
	let nodeAndRecentFile = {};
	
	//items = fs.readdirSync(pathToFolder);
	items = fs.readdirSync(pathToFolder,  { withFileTypes: true }).filter(dirent => !dirent.isDirectory()).map(dirent => dirent.name);
	
	for (let i=0; i<items.length; i++) {
		let gexportFilename = items[i];
		let matches = gexportFilename.match(/(.*)_(\d+)\.xml.*/)
		
		ipcRenderer.send('parse-cm-job', JSON.stringify({status:"info", message: `Checking whether ${gexportFilename} is a duplicate... `}));
		log.info(`[parse_cm_job] Checking whether ${gexportFilename} is a duplicate... `)
		
		if(matches === null) continue;
		
		let node = matches[1];
		let timestamp = matches[2];
		
		if( typeof nodeAndRecentFile[node] === 'undefined'){
			
			nodeAndRecentFile[node] = gexportFilename;
		}else{
			//Get timestamp on file in nodeAndRecentFile
			const mostRecentTimestamp = nodeAndRecentFile[node].match(/(.*)_(\d+)\.xml.*/)[2];

			if(parseInt(timestamp) > parseInt(mostRecentTimestamp)){
				let oldPath = path.join(pathToFolder, nodeAndRecentFile[node])
				let newPath = path.join(repeatedFilesFolder, nodeAndRecentFile[node])
				fs.renameSync(oldPath, newPath)
				
				nodeAndRecentFile[node] = gexportFilename;
			}
			
		}
	}
	
	nodeAndRecentFile = {};
	
	ipcRenderer.send('parse-cm-job', JSON.stringify({status:"info", message: `Duplicate file removal completed.`}))
	log.info(`[parse_cm_job] Duplicate file removal completed.`)
	
}


processCMDumps = async (vendor, format, inputFolder, outputFolder) => {


	
	let basepath = app.getAppPath();

	if (!isDev) {
	  basepath = process.resourcesPath
	} 
	
	const parser = VENDOR_PARSERS[vendor][format]
	const parserPath = path.join(basepath,'libraries',parser)
	
	//Uncompress files for other vendor format combinations except huawei gexport 
	//The reason for this is we want to first remove the duplicates in the dumps, before wasting time 
	//uncompressing what does not need to be uncompressed 
	if(vendor !== 'HUAWEI' && format !== 'GEXPORT_XML'){
		ipcRenderer.send('parse-cm-job', JSON.stringify({status:"info", message: `Uncompressing files...`}))
		log.info(`[parse_cm_job] Uncompressing files...`)
		uncompressFolder(inputFolder);
	}
	
	
	//Clean Huawei GExport files 
	if(vendor === 'HUAWEI' && format === 'GEXPORT_XML'){
		try{
			removeDublicateHuaweiGExportFiles(inputFolder)
						
			ipcRenderer.send('parse-cm-job', JSON.stringify({status:"info", message: `Uncompressing files GExport XML files...`}))
			log.info(`[parse_cm_job] Uncompressing files GExport XML files...`)
			
			uncompressFolder(inputFolder);
			
			ipcRenderer.send('parse-cm-job', JSON.stringify({status:"info", message: `Cleaning GExport XML files...`}))
			log.info(`[parse_cm_job] Cleaning GExport XML files...`)
			
			if(process.platform === "win32"){
				//If windows test, with sed.exe 
				cleanHuaweiGExportWithSed(inputFolder);
			}else{
				await cleanHuaweiGexportFiles(inputFolder);
			}
			
			ipcRenderer.send('parse-cm-job', JSON.stringify({status:"info", message: `Cleanup of GExport XML files completed.`}))
			log.info(`[parse_cm_job] Cleanup of GExport XML files completed.`)
			
		}catch(error){
			log.error('[parse_cm_job] Error occurred:', error);
			ipcRenderer.send('parse-cm-job', JSON.stringify({status:"error", message: error.toString()}))
			return;
		}
		
	}
	
	ipcRenderer.send('parse-cm-job', JSON.stringify({status:"info", message: `Parsing files...`}))
	log.info("[parse_cm_job] Parsing files...")
	
	const child = spawn('java', ['-jar', parserPath, '-i',inputFolder,'-o',outputFolder]);
	
	child.stdout.on('data', (data) => {
	  //console.log(data.toString());
	});

	child.stderr.on('data', (data) => {
	  ipcRenderer.send('parse-cm-job', JSON.stringify({status:"error", message: data.toString()}))
	  log.info(`[parse_cm_job] ${data.toString()}`)
	});
	
	child.on('exit', code => {
		if(code === 0 ){
			ipcRenderer.send('parse-cm-job', JSON.stringify({status:"success", message: `Dump successfully parsed. Find csv files in ${outputFolder}`}))
			log.info(`[parse_cm_job] Dump successfully parsed. Find csv files in ${outputFolder}`)
		}else{
			ipcRenderer.send('parse-cm-job', JSON.stringify({status:"error", message: "Something went wrong"}))
			log.error(`Something went wrong. Error code : ${code}`)
		}
	});

}
	
ipcRenderer.on('parse-cm-job', (event, args) => {
	
	const obj  = JSON.parse(args)
	
	processCMDumps(obj.vendor, obj.format, obj.inputFolder, obj.outputFolder)
})

ipcRenderer.send('ready')

</script>